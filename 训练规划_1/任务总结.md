#### 认识什么是深度学习，常用方法，常用框架

  

---

##### 什么是深度学习

1.深度学习是指通过训练由**多层**网络结构构成的模型来对数据进行回归或分类

2.深度学习作为机器学习的一个子集，优点有：

- 传统机器学习的训练流程往往由多个独立的步骤组成，每个步骤结果的好坏会影响下一步骤的执行结果，从而会影响整个训练结果（非端到端）；而深度学习从模型输入端输入数据，从输出端直接得到结果（**端到端**）。
- 深度学习在训练过程中取代了劳动密集型的特征⼯程。机器学习中模型输入的数据是在原始数据中提取的特征（特征工程和学习模型部分分开）；深度学习通过模型的人工神经网络进行特征的提取的转换（当数据量特别大的时候，特征工程往往不稳定）

---

##### 常用方法

- 批量归一化
- 反向传播
- 随机梯度下降（minisgd）
- 损失函数（平方损失、均方损失）
- 池化
- Dropout
- 填充和卷积运算的步幅

---

##### 常用框架

| 框架名称       |
| -------------- |
| **TensorFlow** |
| **Caffe**      |
| **PyTorch**    |
| **MXNet**      |
| **Keras**      |



---

#### 回顾-典型隐层神经网络的结构

---

#### 卷积神经网络的基本含义以及重要概念-1（卷积原理）

---

#### 卷积神经网络的基本含义以及重要概念-2（填充、步幅）

---

#### 卷积神经网络的基本含义以及重要概念-3（池化、通道）

---

#### 卷积神经网络的基本含义以及重要概念-4（激活函数）

---

#### 卷积神经网络的基本含义以及重要概念-5（Softmax回归）



- softmax回归主要用于分类，和线性回归不同是softmax回归处理的数值是离散的，线性回归的数值是连续的，同时对于有自然顺序的类别也可以转化为回归问题。  

  

- 使用softmax运算将**未规范化的预测值**变换为**非负**且**总和为1**，同时让模型保持**可导**的性质。

**主要过程**：对每个预测值求幂（以e为底数）后除以它们求幂后的总和。  



- softmax运算是非线性函数，但softmax回归的输出仍然**由输⼊特征的仿射变换**决定，所以是线性模型。  

  

- ##### 使用交叉熵损失函数，这里用交叉熵来衡量预测和标号的差异，并将这种差异作为损失

**主要过程**：拿出对应真实标号的预测值，取ln，乘以-1（应为经过softmax运算后都是0<预测值<=1的规范值,因此以e为底的对数值都是<=0的，所以要添上负号，损失通常非负）。  



- 特别注意，当未规范化的预测值**特别大**的时候求幂（以e为底数）后可能会大于数据类型容许的最⼤数字，发生**上溢**（overflow）。

**解决方法**：

1. 在继续softmax计算之前，先从所有**预测值**中减去**max(ok)**（最大预测值）。此时exp(oj − max(ok))后将有接近零的值，发生**下溢**（underflow）。**所以**运算的时候避免exp(oj − max(ok))，⽽直接使⽤oj − max(ok)
2. 针对1.中的问题，将softmax和交叉熵结合在⼀起，可以避免反向传播过程中可能会困扰我们的数值稳定性问题。

---

