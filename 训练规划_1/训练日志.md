### DAY1



##### 完成实验环境的搭建





---

---

网页学习部分





##### 什么是神经网络

人工神经网络是受到人类大脑结构的启发而创造出来的

训练深度神经网络的过程就叫做深度学习





##### 将数据输入神经网络

（1）对于图像，计算机要存储三个独立的矩阵（三个**通道**）分别对应红、绿、蓝，矩阵里面的**数值**就对应于图像的红绿蓝**强度值**

（2）一般将3个矩阵转化成1个**向量**x（向量可以理解成1 * n或n * 1的数组，前者为行向量，后者为列向量

![image-20221020183623969](https://github.com/weiyuanhong623/Deep-learning/blob/main/images/image-20221020183623969.png)

（3）每一个输入到神经网络的数据都被叫做一个特征，由二维矩阵变成的**向量**就叫做**特征向量**，向量的长度就是该向量的**维度**。神经网络接收这个特征向量x作为输入，并进行预测，然后给出相应的结果。

```
eg:
对于一张20*20*20像素的图像 在计算机中有三个二维矩阵进行存储，转为向量后规格为：1*(20*20*3)或(20*20*3)*1，该向量维度就是1200，这张图像就有1200个特征
```





**总结**：不同应用场景所输入的数据在计算机中都有对应的数字表示形式，将其化成一个特征向量，然后将其输入到神经网络中





##### 神经网络如何进行预测



向量相乘（对应元素相乘再相加）

```
dot(w,x)
```



场景：对某一事件进行预测

输入：影响事件发展结果因素（特征），并对特征赋予不同的**权重**，设置不同输出对应的事件结果

输出：预测结果





##### 激活函数——sigmoid

![image-20221020185827218](https://github.com/weiyuanhong623/Deep-learning/blob/main/images/image-20221020185827218.png)

z越大越接近1，越小越接近0







如用于分类： 若输出经过sigmoid的隐藏层后输出为0.8，说明有80%的概率是目标类别





---

---



##### 《drive into deeplearning》学习部分





任⼀调整参数后 的程序，我们称为**模型**（model）。

通过操作参数⽽⽣成的所有不同程序（输⼊-输出映射）的集合称为“**模 型族**”

使⽤数据集来选择参数的元程序被称为**学习算法**（learning algorithm）。





#### 机器学习的一些关键组件



1.数据

（1）数据由**样本**组成，每个样本由被称为**特征**的属性组成，机器学习**模型**会根据这些属性进⾏预测。如在**监督学习问题**中，要预测的是⼀个特殊的属 性，它被称为**标签**（label，或⽬标（target））。

（2）与传统机器学习⽅法相⽐，深度学习的⼀个主要优势是可以处理**不同⻓度的数据**。

（3）更多的数据意味着可以**减少对预先设想假设的依赖**（数据集的由⼩变⼤为现代深度学习的成功奠定基础）

（4）要**筛除无效数据**以及注意数据集的**均衡问题**



2.模型

深度学习与经典⽅法的区别主要在于：前者关注的功能强⼤的模型，这些模型由神经⽹络错综复杂的交织在⼀起，包含层层数据转换，因此被称为深度学习（deep learning）。



3.目标函数

（1）定义模型的**优劣程度的度量**，这个度量在⼤多 数情况是“**可优化**”的，我们称之为⽬标函数（objective function），有时被称为损失函数。

（2）通常，损失函数是**根据模型参数**定义的，并取决于数据集。最常⻅的损失函数是平⽅误差（squared error）

（3）总的流程是：通过**最⼩化总损失**来学习 模型**参数**的**最佳值**。这里是获取**损失**。



4.优化算法

（1）**搜索出最佳参数**，以最⼩化损失函数（⼤多流⾏的优化算法通常基于⼀种基本⽅法‒梯度下 降）。在每个步骤中，梯度下降法都会检查每个参数，看看如果你仅对该参数 进⾏少量变动，训练集损失会朝哪个⽅向移动。然后，它在可以**减少损失的⽅向**上优化参数。







#### 机器学习的类别

##### 1.监督学习

（1）在“给定输⼊特征”的情况下预测标签。每个“**特征-标签**”对都称为 ⼀个样本（example）。估计给定输⼊特征的标签。

（2）监督学习过程：从已知数据集中随级选取一个子集，给子集中的每个样本获取真实标签（有的样本已有标签；有的需要人工标记），输入的特征和标签构成训练集通过**学习算法**输出**模型**，然后使用测试集特征进行输入，模型的输出作为对输入特征的标签的预测。



###### 监督学习的细分：



##### 回归

本质由输出决定，输出的预测标签取任意数值。⽬标是⽣成⼀个模型，它的预测⾮常接近实际标签值。



##### 分类

在分类中，我们训练⼀个**分类器**，它的输出即为预测的类别。

- 模型预测样本属于哪个类别。最简单的分类问题是只有两类，我们称之为“**⼆元分类**”。

- 有两个以上的类别时，我们把这个问题称为**多元分类**（multiclass classification）问题。
- 寻找层次结构，层次 结构假定在许多类之间存在某种关系。**层次分类**（如对动物进行层次分类）



##### 标记问题

学习预测**不相互排斥的类别**的问题称为**多标签分类**



##### 搜索

模型要输出**有序**的**元素⼦集**。可以先为集合中的每个元素分配相应的**相关性分数**，然后**检索**评级最⾼的元素。



##### 推荐系统

向特定⽤⼾进⾏“个性化” 推荐。推荐系统会为“给定⽤⼾和物品”的匹配性打分，这个“分数”可能是估计 的评级或购买的概率，然后检索得分最⾼的对象集推给用户



##### 序列学习

