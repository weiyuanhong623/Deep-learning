#### DAY 37

#### 图像增广

##### 1.背景：

（1）⼤型数据集是成功应⽤深度神经⽹络的先决条件。

（2）图像增⼴在对训练图像进⾏⼀系 列的**随机变化**之后，⽣成**相似但不同**的训练样本，从⽽**扩⼤了训练集的规模。**

（3）应⽤图像增⼴的**原因**是， 随机改变训练样本可以**减少模型对某些属性的依赖**，从⽽**提⾼模型的泛化能⼒。**（eg：以不同的⽅式**裁剪**图像，使感兴趣的对象出现在不同的位置，减少模型对于对象出现**位置的依赖**；调整**亮度**、 颜⾊等因素来降低模型**对颜⾊的敏感度**。）

2.apply的实现

```python
#aup：各种transform方法
def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):
    Y = [aug(img) for _ in range(num_rows * num_cols)]
    d2l.show_images(Y, num_rows, num_cols, scale=scale)
    d2l.plt.show()
```

<br>

##### 多种图像增广方法结合：

![image-20221127195210927](C:\Users\china\AppData\Roaming\Typora\typora-user-images\image-20221127195210927.png)

<br>

注意：在预测过程中得到确切的结果，我们通常**对训练样本只进⾏图像增⼴**，且在**预测过程中不使⽤随机操作的图像增⼴**。同时使⽤**ToTensor实例**将⼀批图像**转换**为深度学习框架所要求的**格式**，即形状为（**批量⼤⼩，通道数，⾼度，宽度**）的**32位浮点数**，取值**范围为0到1**。

```python
train_augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomHorizontalFlip(), #或其他
    torchvision.transforms.ToTensor()])

test_augs = torchvision.transforms.Compose([
	torchvision.transforms.ToTensor()])
```

<br>

#### 微调

1.迁移学习：

（1）背景：训练样本数量有限，训练模型的准确性可能⽆法满 ⾜实际要。

（2）迁移学习（transfer learning）将**从源数据集学到的知识迁移到⽬标数据集**。例如：尽管ImageNet数据集中的⼤多数**图像与椅⼦⽆关**，但在此数据集上**训练的模型可能会提取更通⽤的图像特征**， 这**有助于识别边缘、纹理、形状和对象组合**。这些类似的特征也**可能**有效地识别椅⼦。

2.微调（迁移学习的常见技巧）

<br>

#### 目标检测（object detection）或⽬标识别（object recognition）、边界框

##### 1.概念：

对于图像中感兴趣的目标，不仅想知道它们的**类别**，还想得到它们在图像中的**具体位置**。

##### 2.边界框

（1）通常使⽤边界框（bounding box）来描述对象的**空间位置**。边界框是矩形的，由矩形左上⻆的以及右下⻆的x和y坐标决定。另⼀种常⽤的边界框表⽰⽅法是边界框中⼼的(x, y)轴坐标以及框的宽 度和⾼度。

##### （2）图像中坐标的原点是图像的左上⻆，向右的⽅向为x轴的 正⽅向，向下的⽅向为y轴的正⽅向。

搁置......

<br>

### 语义分割

##### 1.概念：

语义分割重点关注于如何将图像分割成属于**不同语义类别的区域**。 与⽬标检测不同，语义分割可以识别并理解图像中每⼀个像素的内容：其**语义区域的标注和预测是像素级的**。 与⽬标检测相⽐，语义分割标注的像素级的边框 显然**更加精细**。

2.语义分割、图像分割、实例分割区别

（1）**图像分割**将图像划分为**若⼲组成区域**，这类问题的⽅法**通常利⽤图像中像素之间的相关性**。它在**训练 时不需要有关图像像素的标签信息**，在预测时也**⽆法保证**分割出的区域具有我们希望得到的语义。

（2）**实例分割**也叫**同时检测并分割**（simultaneous detection and segmentation），它研究如何识别图像中 各个⽬标实例的像素级区域。与语义分割不同，实例分割**不仅需要区分语义（类别），还要区分不同的⽬标实例（不同个体）。**例如，如果图像中有两条狗，则实例分割需要区分像素属于的两条狗中的哪⼀条。



⭐tips：

1.pycharm无法成功显示图像

```python
d2l.plt.imshow(img)
d2l.plt.show()      #额外加上。为了显示图像
```

2.os.path.join无法找到去检测文件名

<br>

<br>

<br>

#### DAY 38

##### tensor.permute

返回原始张量的视图,并将其尺寸进行了调整

###### 如图片img的size是（28，28，3）就可以利用img.permute(2,0,1)得到一个size为（3，28，28）的tensor

```python
x=torch.arange(24).reshape((2,4,3))
print(x)
print(type(x))
print(x.shape)

x=x.permute(1,2,0)
print(x)
print(x.shape)


tensor([[[ 0,  1,  2],
         [ 3,  4,  5],
         [ 6,  7,  8],
         [ 9, 10, 11]],

        [[12, 13, 14],
         [15, 16, 17],
         [18, 19, 20],
         [21, 22, 23]]])
<class 'torch.Tensor'>
torch.Size([2, 4, 3])
tensor([[[ 0, 12],
         [ 1, 13],
         [ 2, 14]],

        [[ 3, 15],
         [ 4, 16],
         [ 5, 17]],

        [[ 6, 18],
         [ 7, 19],
         [ 8, 20]],

        [[ 9, 21],
         [10, 22],
         [11, 23]]])
torch.Size([4, 3, 2])
```

⭐

##### 注意具体数值的分配方式：

- 依次横向变成依次竖向
- 相当于把**第一个矩阵的行和第二个矩阵的行** **分别变列** **对应组合** 形成新的矩阵

<br>

#### DAY 39

##### 语义分割-预处理数据

1.问题：之前是通过缩放图像使其符合模型的输⼊形状。在语义分割中，这样做需要将预测的像素类别重新映射回原始尺⼨的输⼊图像。这样的映射可能不够精确，尤其在不同语义的 分割区域。

2.解决方法：将图像**裁剪为固定尺⼨**，**⽽不是缩放**。具体来说，我们使⽤图像增⼴ 中的随机裁剪，**裁剪输⼊图像和标签的相同区域。**

- 由于语义分割的输⼊**图像和标签在像素上⼀⼀对应**，输⼊图像会被随机裁剪为固定尺⼨⽽不是缩放。

<br>

#### 转置卷积

##### 1.背景

到⽬前为⽌的卷积神经⽹络层，通常会减少**下采样**输⼊图像的空间维度（⾼和宽）。然⽽**如果输⼊和输出图像的空间维度相同**，在以**像素级分类**的语义分割中将会很**⽅便**。例如，**输出像素所处的通道维可以保有输⼊像素在同⼀位置上的分类结果**。

##### 2.总述

大多数情况是空间维度**被卷积神经⽹络层缩⼩后**，可使⽤另⼀种类型的卷积神经⽹络 层，它可以**增加上采样中间层特征图的空间维度**。在本节中，我们将介绍 **转置卷积（transposed convolution）**。⽤于**逆转下采样导致的空间尺⼨减⼩（上采样）**。

##### 3.具体操作

- 转置卷积通过卷积核“**⼴播**”输⼊元素，从⽽ 产⽣⼤于输⼊的输出。

- stride=1、nk,nw的输入张量、kh,kw的卷积核

- 以**步幅为1滑动卷积核窗⼝**，**每⾏nw次**，**每列nh次**，共产⽣**nh*nw**个中间结果。每个 **中间结果**都是⼀个**(nh + kh − 1) × (nw + kw − 1)的张量**，**初始化为0**。输⼊张量中的**每个元素**都要**乘以卷积核**，从⽽使所得的**kh × kw**张量替换中间张量的⼀部分。

eg：

nh=nw=2,kh=kw=2,stride=1

中间张量高、宽是nh-kh+1=3,是(3,3)，进行替换的张量是(2,2)

![image-20221128230329958](C:\Users\china\AppData\Roaming\Typora\typora-user-images\image-20221128230329958.png)

```python
#对于普通的2维转置卷积运算
def trans_conv(X,K):
    h,w=K.shape
    Y=torch.zeros((X.shape[0]+h-1,X.shape[1]+w-1))  #初始化
    for i in range(X.shape[0]):
        for j in range(X.shape[1]):         #stride=1，从左到右，从上到下，依次对每个元素进行
            Y[i:i+h,j:j+w]+=X[i,j]*K        #替换区域使用替换张量替换，替换张量由输入元素乘以k得到
    return Y

X=torch.tensor([[0.0,1.0],
                [2.0,3.0]])
K=torch.tensor([[0.0,1.0],
                [2.0,3.0]])
Z=trans_conv(X,K)
print(Z)

tensor([[ 0.,  0.,  1.],
        [ 0.,  4.,  6.],
        [ 4., 12.,  9.]])
```

<br>

当输⼊X和卷积核K都是**四维张量**时，我们可以使⽤⾼级API获得相同的结果。

```python
X=torch.tensor([[0.0,1.0],[2.0,3.0]])
K=torch.tensor([[0.0,1.0],[2.0,3.0]])

X,K=X.reshape(1,1,2,2),K.reshape(1,1,2,2)
tconv=nn.ConvTranspose2d(1,1,kernel_size=2,bias=False)  #批量大小是1 通道数是1
tconv.weight.data=K     #指定卷积核数据⭐
Z=tconv(X)
print(Z)


tensor([[[[ 0.,  0.,  1.],
          [ 0.,  4.,  6.],
          [ 4., 12.,  9.]]]], grad_fn=<ConvolutionBackward0>)
```

##### 4.填充、步幅、多通道

##### （1）填充

在转置卷积中，**填充被应⽤于的输出**（**常规卷积将填充应⽤于输⼊**）

eg：⭐padding=1时，转置卷积的输出中将**删除第⼀和最后的⾏与列**（pd=1，上下各删除1）。

```python
tconv=nn.ConvTranspose2d(1,1,kernel_size=2,padding=1,bias=False)  

>>>
tensor([[[[4.]]]], grad_fn=<ConvolutionBackward0>)
```

⭐进一步直观理解：

- **padding作用在输出上**（这里这个输出指的说就是**维度是4，单元素4的张量**），padding=1，上下左右各填充1，得到3*3，然后再通过**同样参数（只是k大小相同，padding=0,stride=1）的卷积操作**3-2+1=2，可以得到之前的（2，2）的高宽。
- 因此加了padding实际上是使得**输出变小**的。

##### （2）步幅

在转置卷积中，**步幅被指定为中间结果（输出）**，⽽不是输⼊。

eg：stride=2，会增加中间张量的⾼和权重

```python
tconv=nn.ConvTranspose2d(1,1,kernel_size=2,stride=2,bias=False)  


tensor([[[[0., 0., 0., 1.],
          [0., 0., 2., 3.],
          [0., 2., 0., 3.],
          [4., 6., 6., 9.]]]], grad_fn=<ConvolutionBackward0>)
```

##### （3）多通道输入和输出

- 转置卷积与常规卷积以相同⽅式运作。假设**输⼊有ci个通道**，且转置卷积为每个输⼊通道分配了⼀个kh × kw的卷积核张量。当指定**多个输出通道时**，**每个输出通道**将有⼀个**ci × kh × kw的 卷积核**。
- 如果我们将X代⼊卷积层f来输出Y = f(X)，并创建⼀个与f具有相同的超参数、但输出通道数量是X中 通道数的转置卷积层g，那么g(Y )的形状将与X相同。

```python
#主要用途
X2 = torch.rand(size=(1, 10, 16, 16))
print(X2)
conv=nn.Conv2d(10,20,kernel_size=5,padding=2,stride=3)      #(nh-5+2*2+3)//3 =(16-5+7)//3=18//3=6
tconv=nn.ConvTranspose2d(20,10,kernel_size=5,padding=2,stride=3)    #

flag=tconv(conv(X2)).shape == X2.shape
print(flag)

True
```

<br>

<br>

<br>

#### DAY 40

##### 为什么被称为“转置”

（1）之前的卷积操作

![image-20221129104249013](C:\Users\china\AppData\Roaming\Typora\typora-user-images\image-20221129104249013.png)

V是一个比较大的矩阵。

W理解为K

Y`：(m)、V：(m,n)、	**把X展平成向量**

X`:(n)	

###### 将卷积变化为矩阵乘法

<br>

![image-20221129104413325](C:\Users\china\AppData\Roaming\Typora\typora-user-images\image-20221129104413325.png)

Y`：(n)、Vt：(n,m)转置、

X`:(m)	

<br>

##### 总的来说：使用和卷积同样参数的转置卷积可以得到原来的高宽

<br>

#### 与矩阵变换的联系

1.由K求取W矩阵

```python
#包含⼤量0的稀疏权重矩阵W。权重矩阵的形状是（4，9），其中⾮0元素来⾃卷积核K。
def kernel2matrix(K):
    k, W = torch.zeros(5), torch.zeros((4, 9))
    k[:2], k[3:5] = K[0, :], K[1, :]        #k的前2个元素由卷积核的第二列替换，k后两个由第二列替换，k共5个元素，中间为0
    W[0, :5], W[1, 1:6], W[2, 3:8], W[3, 4:] = k, k, k, k
    return W
```

2.**逐⾏连结输⼊X**，获得了⼀个⻓度为9的**向量**（矢量）。然后，**W的矩阵乘法和向量化的X给出了⼀个⻓度为4的向量**。**重 塑Y**之后，可以获得与上⾯的原始卷积操作所得相同的结果Y：我们刚刚使⽤**矩阵乘法实现了卷积。**

```python
X=torch.arange(9.0).reshape(3,3)
K=torch.tensor([[1.0,2.0],
                [3.0,4.0]])

Y=d2l.corr2d(X,K)       #卷积运算
print(Y)

#包含⼤量0的稀疏权重矩阵W。权重矩阵的形状是（4，9），其中⾮0元素来⾃卷积核K。
def kernel2matrix(K):
    k, W = torch.zeros(5), torch.zeros((4, 9))
    k[:2], k[3:5] = K[0, :], K[1, :]        #k的前2个元素由卷积核的第二列替换，k后两个由第二列替换，k共5个元素，中间为0
    W[0, :5], W[1, 1:6], W[2, 3:8], W[3, 4:] = k, k, k, k
    return W

W=kernel2matrix(K)
print(W)		

#(4,9)  (9)
Y2=torch.matmul(W,X.reshape(-1)).reshape(2,2)       #将x转为向量和W进行矩阵乘法得到(1,4)，然后重塑为(2,2)

print(Y2)
```

<br>

#### 也可转化为矩阵进行转置矩阵的运算

```python
#也可实现转置卷积
Z=trans_conv(Y,K)
Z2=torch.matmul(W.T,Y.reshape(-1)).reshape(3,3)
print(Z)

#
tensor([[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]])
tensor([[27., 37.],
        [57., 67.]])
tensor([[ 27.,  91.,  74.],
        [138., 400., 282.],
        [171., 429., 268.]])
```

**抽象**来看，给定**输⼊向量x和权重矩阵W**，卷积的**前向传播**函数可以通过将其**输⼊与权重矩阵相乘**并输出**向 量y = Wx来实现**。由于**反向传播遵循链式法则**和![image-20221129113309264](C:\Users\china\AppData\Roaming\Typora\typora-user-images\image-20221129113309264.png)，卷积的反向传播函数可以通过将其**输⼊与转置 的权重矩阵W⊤**相乘来实现。因此，转置卷积层能够交换卷积层的正向传播函数和反向传播函数：**它的正向 传播和反向传播函数将输⼊向量分别与W⊤和W相乘。**

<br>

##### ⭐进两步理解转置卷积的padding、stride

#### 转置卷积本质上还是一种卷积，同反卷积不一样，反卷积得到的值也相同，转置卷积只是形状相同，以达到上采样的目的。

（1）n=2,k=2,**pd=0,**stride=1时：

将输入**填充k-pd-1**得到(4,4)，因为2*(k-1)，是上下、左右所以乘以2。接着将**卷积核上下、左右翻转**，最后进行**卷积运算**就得到转置卷积该有的输出。

![image-20221129144433661](C:\Users\china\AppData\Roaming\Typora\typora-user-images\image-20221129144433661.png)

（2）推广：n=2,k=2,**pd=p**,stride=1:

将输入**填充k-p-1**。这里pd=1，得到(2,2)，因为2*(k-1)，是上下、左右所以乘以2。接着将**卷积核上下、左右翻转**，最后进行**卷积运算**就得到转置卷积该有的输出。

![image-20221129144708997](C:\Users\china\AppData\Roaming\Typora\typora-user-images\image-20221129144708997.png)

##### ⭐（3）推广：n=2,k=2,pd=p,stride=s

- 在**行和列之间插入s-1行或列**。这里s=2,s-1=1，插入完就是3*3

- 将输入**填充k-p-1**。**这里pd=0**，得到(2,2)，因为2*(k-1)，是上下、左右所以乘以2。（填充和插入的的元素都是0）

- 将**卷积核上下、左右翻转**
- **卷积运算**就得到转置卷积该有的输出。

![image-20221129150621290](C:\Users\china\AppData\Roaming\Typora\typora-user-images\image-20221129150621290.png)

###### 2*2+2-2=4，（4，4）

##### （4）形状换算

输入高、宽n，核k，填充p，步幅s

- 转置卷积n1=s*n+k-2p-s
- 卷积n2=(n-k+2p+s)//s  **n>=s*n2+k-2p-s**（即由卷积得到的高、宽进行转置卷积还原的高宽<=原高宽。能**n2那里整除**的时候是=的）
- 要使**高宽成倍增加**，那么**k=2p+s**（具体过程中先确定strdie，pd凭经验，然后凑k）

<br>

#### 全连接网络（FCN）

1.总述：

（1）全卷积⽹络（fully convolutional network， FCN）采⽤卷积神经⽹络实现了从**图像像素**到**像素类别**的变换。

（2）全卷积⽹络将**中间层特征图**的**⾼和宽**变换回**输⼊图像的尺⼨**（通过转置卷积），**输出的类别预测**与**输⼊图像**在 **像素级别上**具有**⼀⼀对应关系**：**通道维的输出即该位置对应像素的类别预测**。

##### 3.结构

⭐（1）卷积神经网络**抽取图像特征**，然后通过**（1，1）卷积层**将**通道数转变为类别数**，接着通过**转置卷积层**将特征图的高、宽变换为输入图像的尺寸（此时输出和输入的高、宽相同）。最终输出通道包含了该**空间位置像 素的类别预测**。

<br>

⭐卷积高宽的计算实例：对于（320，480）的一张图片，经过**resnet18**的卷积部分得到的高宽：

（320-64+2*16+32）//32=10

（480-64+2*16+32）//32=15

<br>

##### 初始化转置卷积层

1.**双线性插值**（bilinear interpolation） 是常⽤的**上采样⽅法之⼀**，它也经常⽤于**初始化转置卷积层**。

2.具体过程：

给定输⼊图像，计算**上采样输出图像**上的每个像素。⾸先，将输出图像 的**坐标(x, y)映射到输⼊图像的坐标(x ′ , y′ )上。**例如，根据输⼊与输出的**尺⼨之⽐**来映射。请注意，**映射后 的x′和y′是实数**。然后，**在输⼊图像上找到离坐标(x ′ , y′ )最近的4个像素。**最后，输出图像在坐标(x, y)上的像 素依据输⼊图像上这4个像素及其与(x ′ , y′ )的相对距离来计算。 **双线性插值的上采样可以通过转置卷积层实现，内核由以下bilinear_kernel函数构造。**

<br>

##### detach()

（1）detach()返回一个新的tensor，是从当前计算图中分离下来的，但是仍指向原变量的存放位置，其grad_fn=None且requires_grad=False，得到的这个tensor永远不需要计算其梯度，不具有梯度grad，即使之后重新将它的requires_grad置为true,它也不会具有梯度grad。



（2）如果A网络的输出被喂给B网络作为输入， 如果我们希望在梯度反传的时候只更新B中参数的值，而不更新A中的参数值，这时候就可以使用`detach()`。



### RreNet18+FCN

![image-20221129213028568](C:\Users\china\AppData\Roaming\Typora\typora-user-images\image-20221129213028568.png)

```
loss 0.388, train acc 0.905, test acc 0.904
total time:  0.021223501364390055  min
```



<br>

⭐tips对于

![image-20221129212708493](C:\Users\china\AppData\Roaming\Typora\typora-user-images\image-20221129212708493.png)

解决方法：修改进程数为0

